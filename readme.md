# Autonomous Vehicle Simulation Data Analysis Pipeline

A comprehensive end-to-end pipeline for autonomous vehicle simulation data analysis using modern data engineering and machine learning tools.

## ğŸ—ï¸ Architecture Overview

```
Kafka Producer â†’ Kafka Cluster â†’ Flink (Real-time Processing) â†’ HDFS/S3 Storage
                                      â†“
Spark (Batch Processing) â†’ ML Training (PyTorch/TensorFlow) â†’ MLflow Tracking
                                      â†“
Real-time Inference â†’ Dash Dashboard â†’ Monitoring (Prometheus/Grafana)
```

## ğŸ› ï¸ Tech Stack

- **Streaming**: Apache Kafka
- **Real-time Processing**: Apache Flink (PyFlink)
- **Batch Processing**: Apache Spark (PySpark)
- **ML Frameworks**: PyTorch, TensorFlow
- **ML Tracking**: MLflow
- **Storage**: AWS S3, HDFS
- **Visualization**: Dash/Plotly
- **Orchestration**: Docker, Kubernetes
- **Monitoring**: Prometheus, Grafana

## ğŸ“ Project Structure

```
â”œâ”€â”€ kafka_producer/          # Kafka data producers
â”œâ”€â”€ flink_processor/         # Real-time stream processing
â”œâ”€â”€ spark_jobs/             # Batch processing jobs
â”œâ”€â”€ ml_training/            # ML model training scripts
â”œâ”€â”€ ml_inference/           # Real-time inference services
â”œâ”€â”€ mlflow_tracking/        # MLflow configurations
â”œâ”€â”€ storage_utils/          # S3/HDFS utilities
â”œâ”€â”€ dashboard/              # Dash visualization
â”œâ”€â”€ docker/                 # Docker configurations
â”œâ”€â”€ k8s/                    # Kubernetes manifests
â”œâ”€â”€ monitoring/             # Prometheus/Grafana configs
â”œâ”€â”€ config/                 # Configuration files
â”œâ”€â”€ scripts/                # Utility scripts
â””â”€â”€ docs/                   # Documentation
```

## ğŸš€ Quick Start

1. **Prerequisites**: WSL2, Docker, Docker Compose
2. **Setup Environment**: `./scripts/setup.sh`
3. **Start Services**: `docker-compose up -d`
4. **Run Pipeline**: Follow phase-by-phase instructions below

## ğŸ“‹ Phase-by-Phase Implementation

### Phase 1: Infrastructure Setup

- Kafka + Zookeeper cluster
- HDFS setup
- MLflow tracking server

### Phase 2: Data Ingestion

- Kafka producer for sensor data simulation
- Data schema definition

### Phase 3: Real-time Processing

- Flink jobs for stream processing
- Data validation and enrichment

### Phase 4: Batch Processing

- Spark jobs for data preprocessing
- Feature engineering pipelines

### Phase 5: ML Training

- Object detection model training
- MLflow experiment tracking

### Phase 6: Real-time Inference

- Model serving infrastructure
- Real-time prediction pipeline

### Phase 7: Visualization

- Dash dashboard for monitoring
- Real-time metrics display

### Phase 8: Deployment

- Kubernetes deployment
- Monitoring and alerting

## ğŸ”§ Development Environment

This project is optimized for:

- **WSL2** on Windows
- **Docker** containerization
- **VS Code** development environment
- **Cross-platform** compatibility

## ğŸ“š Documentation

- [Setup Guide](docs/setup.md)
- [API Reference](docs/api.md)
- [Deployment Guide](docs/deployment.md)
- [Troubleshooting](docs/troubleshooting.md)

## ğŸ¤ Contributing

Please read our [Contributing Guide](CONTRIBUTING.md) for details on our code of conduct and development process.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
